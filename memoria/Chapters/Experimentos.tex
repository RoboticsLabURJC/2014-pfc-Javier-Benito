% Chapter Template

\chapter{Experimentos}

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

En este capítulo se detallarán las pruebas realizadas, con el objetivo de validar la solución propuesta en este trabajo. Además, se comprobarán las diferentes configuraciones desarrolladas y se evaluarán sus prestaciones con los costes temporales. Estos experimentos han permitido depurar el componente para ajustar y mejorar la funcionalidad del mismo durante el desarrollo.

%-----------------------------------
%	SECTION Validación experimental
%-----------------------------------
\section{Validación experimental}

El entorno de pruebas utilizado ha sido siempre un entorno real, trabajando con los datos en vivo proporcionados por OpenniServer que extrae la información directamente del sensor RGBD.

Se propone en esta sección validar el componente en las diferentes fases unitarias que lo componen: detección de puntos de interés, cálculo de emparejamientos y estimación de movimiento.

\subsection{Detección de puntos de interés}

La detección de puntos de interés resulta una tarea sencilla si nos ayudamos de OpenCV. En esta sección veremos algunos ejemplos de las diferencias entre técnicas empleadas, y el filtro frontera.

En la Figura~\ref{fig:sift-surf} se puede ver la extracción de puntos de interés tanto con SIFT como con SURF, aparentemente no hay grandes diferencias. Como se vió en el capítulo~\ref{Chapter4} el cálculo de puntos de interés es muy similar y la diferencia fundamental radica en el tiempo de cómputo.

\begin{figure}[th]
\centering
\includegraphics[scale=0.6]{Figures/tests/sift-surf.png}
\decoRule
\caption[Extracción de características con SURF y con SIFT]{Extracción de características con SURF (a), y con SIFT (b).}
\label{fig:sift-surf}
\end{figure}

\subsubsection{Efecto del filtro de puntos frontera}

En la Figura~\ref{fig:borderfilter} tenemos el resultado de aplicar el filtro frontera sobre una misma imagen. Como se puede observar, al añadir el filtro frontera se eliminan algunos de los puntos más controvertidos de la imagen, como son los puntos a lo largo del marco de la puerta o del mástil de la guitarra.

\begin{figure}[th]
\centering
\includegraphics[scale=0.7]{Figures/tests/borderfilter.png}
\decoRule
\caption[Captura de la extracción de puntos de interés con filtro frontera]{Captura de la extracción de puntos de interés con filtro frontera (a), y sin filtro (b).}
\label{fig:borderfilter}
\end{figure}

\subsection{Cálculo de emparejamientos}

Para probar el cálculo de los emparejamientos se somete el componente a cambios de traslación y rotación para comprobar la veracidad de los puntos emparejados. Se parte, como se explicó en el anterior capítulo \ref{Chapter4}, de los $20\%$ mejores emparejamientos medidos por distancia, ya que en condiciones normales se tienen unos $300$ y el $20\% (60)$ es un número razonable de puntos y se asegura consistencia.

\subsubsection{Necesidad del filtro de sobresaliencia}

En la Figura~\ref{fig:error-matching} se puede observar cómo en condiciones normales se ha producido un error en el emparejamiento de dos puntos de interés. Como vimos en el capítulo~\ref{Chapter4}, es debido a que los descriptores de esos puntos son los más similares y muy parecidos a todos los que, en este caso, forman el marco de la puerta.

%y es debido a que los descriptores de esos dos puntos son los más similares. Al estar en una zona muy parecida se puede entender que la correlación es muy similar en todos los puntos correspondientes, en este caso, al marco de la puerta. 

\begin{figure}[th]
\centering
\includegraphics[scale=0.6]{Figures/tests/matching-error.png}
\decoRule
\caption[Captura con un error de emparejamiento sin filtro de sobresaliencia]{Captura de un emparejamiento erróneo en condiciones normales.}
\label{fig:error-matching}
\end{figure}

Este caso se ha buscado a propósito para justificar la necesidad del \textbf{filtro de sobresaliencia}. En todas las pruebas de ahora en adelante se ha incluido para añadir robustez a los experimentos y evitar estos casos de malos emparejamientos que estropean si no el cálculo tridimensional.

\subsubsection{Funcionamiento en Traslación y Rotación}

En la Figura~\ref{fig:matching-rt} se puede observar el resultado de aplicar los emparejamientos bajo circunstancias de traslación y rotación. Como se puede ver en los emparejamientos obtenidos, el resultado es el esperado y no hay error.

\begin{figure}[th]
\centering
\includegraphics[scale=0.6]{Figures/tests/matching-rt.png}
\decoRule
\caption[Captura con los emparejamientos con imágenes sometidas a una rotación y a una traslación]{Captura de los emparejamientos con imágenes sometidas a una traslación y a una rotación, respectivamente.}
\label{fig:matching-rt}
\end{figure}

\subsection{Resolución 3D}

La resolución 3D o estimación de movimiento compone el último paso que completa una iteración del sistema, por lo que en esta etapa podremos ver el resultado final del movimiento entre varios fotogramas consecutivos.

Las pruebas mostradas a continuación son realizadas con un funcionamiento normal del componente y en un tiempo determinado. El objetivo de estos experimentos es comprobar el comportamiento del sistema para los diferentes tipos de traslaciones ($x$, $y$, y $z$) y rotaciones (\textit{pitch}, \textit{yaw}, \textit{roll}).

Para estas pruebas y las siguientes se hará uso del componente con el comportamiento automático activado, repitiendo así de manera automática cada ciclo de estimación 3D. También se han incorporado en ellas, para añadir robustez, el filtro de sobresaliencia y RANSAC.

\subsubsection{Validación de la traslación}

En esta subsección se describen pruebas para comprobar cómo se comporta el sistema ante la traslación. Se movió la cámara a lo largo de los tres ejes ($x$, $y$ y $z$) (Figura~\ref{fig:xyz}).

\begin{figure}[th]
\centering
\includegraphics[scale=0.3]{Figures/xyz.png}
\decoRule
\caption[Ejes de coordenadas $x$, $y$ y $z$]{Ejes de coordenadas $x$, $y$ y $z$, con la orientación de la cámara.}
\label{fig:xyz}
\end{figure}

Para estas pruebas se utiliza el mismo entorno de trabajo por lo que el punto de partida es el que se muestra en la Figura~\ref{fig:init}.

\begin{figure}[th]
\centering
\includegraphics[scale=0.35]{Figures/tests/init.png}
\decoRule
\caption[Punto de partida para las pruebas de traslación y rotación]{Punto de partida para las pruebas realizadas.}
\label{fig:init}
\end{figure}

En la Figura~\ref{fig:axis-y} se muestra la estimación de movimiento sobre el eje $y$. El desplazamiento se ha intentado hacer lo más recto posible y el recorrido se muestra como estela en el visor 3D del componente. En ambas capturas se puede ver la ida y la vuelta recorriendo por cada una 1.5 metros aproximadamente. Después se ha vuelto a la posición de origen del movimiento.

\begin{figure}[th]
\centering
\includegraphics[scale=0.35]{Figures/tests/axis-y.png}
\decoRule
\caption[Prueba con desplazamiento en el eje $y$]{Prueba con desplazamiento en el eje $y$.}
\label{fig:axis-y}
\end{figure}

Se puede observar, después de aproximadamente 100 iteraciones, cómo ha afectado el error a la estimación al volver el sensor al origen.

En la Figura~\ref{fig:axis-xz} se puede ver el efecto de la traslación en los ejes $x$ y $z$ respectivamente. Se ve cómo el error en estos ejes es menor, percibiendo oscilaciones en su mayor parte únicamente en el eje $y$. La validación del eje $x$ se ha realizado sobre una mesa recorriendo 1 metro, por lo que no se obtiene desplazamiento en $z$. En cuanto a las pruebas del eje $z$ se aprecia un balanceo en $x$ debido al movimiento vertical de la mano ya que no ha seguido una trayectoria recta.

\begin{figure}[th]
\centering
\includegraphics[scale=0.35]{Figures/tests/axis-x-z.png}
\decoRule
\caption[Prueba con desplazamiento en los ejes $x$ y $z$]{Prueba con desplazamiento en los ejes $x$ y $z$.}
\label{fig:axis-xz}
\end{figure}

Los resultados son aceptables en la estimación 3D. No se consigue un cierre de trayectoria perfecto pero se acerca bastante a ello. Pensando que se ha aplicado una traslación de más de 1 metro el error final obtenido se puede medir en centímetros, acentuándose más para el eje $y$ correspondiente al perpendicular al plano imagen y el que se obtiene de la imagen de profundidad.

Como vimos en el capítulo~\ref{Chapter3} la información de profundidad del sensor no es perfecta y tiene un pequeño margen de error. Aparte de tener un rango de distancias óptimo establecido por el fabricante (\textit{0.8 to 3.5 m}), fuera de este rango la imagen de profundidad empieza a empeorar drásticamente y por consiguiente la estimación de movimiento se deteriora.

\subsubsection{Validación de la Rotación}

Se valida ahora la rotación de sensor de los ángulos \textit{pitch}, \textit{yaw} y \textit{roll}. En la Figura~\ref{fig:p-y-r} se tiene un ejemplo gráfico de cuáles son estos movimientos y a qué rotación de ejes pertenecen.

\begin{figure}[th]
\centering
\includegraphics[scale=0.9]{Figures/pitch_yaw_roll.png}
\decoRule
\caption[Explicación gráfica del movimiento \textit{pitch}, \textit{yaw} y \textit{roll}]{Dibujo con los movimientos \textit{pitch}, \textit{yaw} y \textit{roll}.}
\label{fig:p-y-r}
\end{figure}

En la Figura~\ref{fig:pitch} se efectúa una prueba con el ángulo \textit{pitch} y se comprueba cómo el sistema detecta una rotación total de $90º$. Se visualiza el estado de la cámara al orientar hacia arriba el sensor y posteriormente orientarlo paralelo al suelo. 

En cuanto a la traslación, se observa, sin contar con el ruido, que el eje de la cámara se mantiene fijo en el origen, como era de esperar.

\begin{figure}[th]
\centering
\includegraphics[scale=0.35]{Figures/tests/pitch.png}
\decoRule
\caption[Prueba con desplazamiento del ángulo \textit{pitch}]{Prueba con desplazamiento del ángulo \textit{pitch}.}
\label{fig:pitch}
\end{figure}

Para los ángulos \textit{yaw} y \textit{roll} se pueden observar en la Figura~\ref{fig:yaw-roll} las pruebas realizadas. En la primera captura se observa una rotación de $45º$ sobre el eje \textit{yaw} y en la segunda sobre el eje \textit{roll}. En ambos casos el movimiento estimado es el correcto.

\begin{figure}[th]
\centering
\includegraphics[scale=0.35]{Figures/tests/yaw-roll.png}
\decoRule
\caption[Pruebas con desplazamiento en los angulos \textit{yaw} y \textit{roll}]{Pruebas con desplazamiento en los angulos \textit{yaw} y \textit{roll}.}
\label{fig:yaw-roll}
\end{figure}

\subsubsection{Validación de trayectorias combinadas}

En esta subsección se muestra el funcionamiento del componente desarrollado ante trayectorias combinadas. El primer experimento consiste en la realización de un círculo a mano con el sensor RGBD. El resultado del experimento, en diferentes etapas, se puede observar en la Figura~\ref{fig:ex1}. Se aprecia cómo a pesar del movimiento irregular del brazo y el error acumulativo, el resultado obtenido se parece a un círculo.

\begin{figure}[th]
\centering
\includegraphics[scale=0.2]{Figures/tests/ex-1.png}
\decoRule
\caption[Experimento con el cálculo de una trayectoria en forma de círculo]{Experimento con el cálculo de una trayectoria en forma de círculo.}
\label{fig:ex1}
\end{figure}
 
El siguiente experimento se compone de un desplazamiento vertical hacia el eje $z$ y después una rotación del ángulo \textit{roll}. El resultado se visualiza en la Figura~\ref{fig:ex2}.
 
\begin{figure}[th]
\centering
\includegraphics[scale=0.2]{Figures/tests/ex-2.png}
\decoRule
\caption[Experimento con desplazamiento vertical hacia el eje $z$ y después una rotación del ángulo \textit{roll}]{Experimento con desplazamiento vertical hacia el eje $z$ y después una rotación del ángulo \textit{roll}.}
\label{fig:ex2}
\end{figure}


\subsection{Acumulación de error en estático}

El error estático muestra el ruido que se esconde detrás de la resolución 3D en tiempo real. Como se va a poder observar en esta sección, el ruido acumulado en estático es recurrente, está presente en todas las configuraciones del algoritmo y refleja su naturaleza incremental, acumulativa. En el capítulo de conclusiones (\ref{Chapter6}), se sugerirán métodos para poder eliminarlo en mayor o menor medida.

Se han relizado varios experimentos con la cámara quieta, con distintas configuraciones del algoritmo. En cada iteración se incurre en algún ligero error que se va acumulando y hace que pasados 30 o 60 segundos la posición estimada de la cámara sea distinta de la posición real, que no se ha movido nada.

En la Figura (\ref{fig:static}) se puede ver un ejemplo de este error para diferentes configuraciones. Como se puede apreciar, es un error que está presente en todos los casos. Las pruebas realizadas han sido capturadas a los 30 y 60 segundos respectivamente y la configuración aplicada se encuentra en la descripción de la Figura~\ref{fig:static}.

\begin{figure}[th]
\centering
\includegraphics[scale=0.30]{Figures/tests/static.png}
\decoRule
\caption[Capturas con ruido estático]{En la primera imagen se representa el ruido estático después de 30 y 60 segundos, con SURF y FLANN. La segunda con SIFT, Fuerza Bruta y filtros. La tercera con SIFT, Fuerza Bruta y RANSAC.}
\label{fig:static}
\end{figure}

%\begin{figure}[th]
%\centering
%\includegraphics[scale=0.3]{Figures/tests/static-filter_2.png}
%\decoRule
%\caption[Ruido estático, con SIFT, Fuerza Bruta y filtros]{Ruido estático después de 30 y 60 segundos, con SIFT, Fuerza Bruta y filtros.}
%\label{fig:static2}
%\end{figure}
%
%\begin{figure}[th]
%\centering
%\includegraphics[scale=0.3]{Figures/tests/static-ransac_2.png}
%\decoRule
%\caption[Ruido estático, con SIFT, Fuerza Bruta y RANSAC]{Ruido estático después de 30 y 60 segundos, con SIFT, Fuerza Bruta y RANSAC.}
%\label{fig:static3}
%\end{figure}

Si analizamos las matrices RT obtenidas se puede observar que el eje en que más crece el ruido es el eje $y$, el perpendicular al plano imagen, lo que es coherente con las pruebas de la sección anterior. Es precisamente en ese eje donde el algoritmo realizado se comporta peor, donde incurre en más error.

La conclusión a la que se llega con las pruebas realizadas es que el error perjudica más al sistema cuanto mayor es la duración de la estimación, ya que se trata de un error acumulativo.


%-----------------------------------
%	SECTION Tiempos de procesado
%-----------------------------------
\newpage
\section{Tiempos de cómputo del procesamiento}
En esta sección se ven los tiempos de cómputo del componente realizado en este proyecto. Como el componente realiza distintas tareas hasta completar una iteración, se ha desarrollado una funcionalidad que mide el tiempo medio por cada una de ellas cuando se termina la ejecución del componente.

Se ha analizado el tiempo medio para diferentes configuraciones en un intervalo de 10 segundos. Para un uso por defecto de la aplicación, se tienen estos costes computacionales:

\begin{lstlisting}[style=CStyle]
Average times:
- Update images: 0.678057 ms
- Points detection: 134.506 ms
- Points matching: 14.0233 ms
- Estimate matrix: 2.5231 ms
-----------------------------
- TOTAL: 151.731 ms
\end{lstlisting}

Como se puede observar, la detección de puntos es la parte que más tiempo requiere. Por el contrario, la estimación de la matriz RT es la que menos. Esta prueba se ha realizado con una media de unos 300 puntos de interés por iteración. Como es lógico, el tiempo de detección variará con respecto al número de puntos de interés o características extraídas. Estos puntos de interés según las pruebas no solo están condicionados a la imagen que se está analizando, la intensidad de luz también desempeña un papel muy importante en la detección de más o menos características.

En el cuadro~\ref{tab:detection-time} podemos ver la variabilidad de tiempo de detección para diferentes números de puntos.

\begin{table}[h]
\caption{Tiempos medios de detección en relación a los puntos de interés}
\label{tab:detection-time}
\centering
\begin{tabular}{ l | l }
\toprule
\textbf{Número de puntos} & \textbf{Tiempo (ms)}\\
\hline\hline
100 & 102.27\\
\hline
200 & 117.136\\
\hline
250 & 126.019\\
\hline
300 & 134.506\\
\hline
350 & 137.805\\
\hline
400 & 144.408\\
\bottomrule
\end{tabular}
\end{table}

%En esta etapa se ha incluído además el cálculo de puntos de interés 2D a nube de puntos 3D ya que es necesaria para la siguiente etapa.

La diferencia entre los distintos algoritmos y filtros no se nota en exceso en cuanto a tiempos, sin embargo, al utilizar SURF con respecto a SIFT se ha notado una reducción hasta de 10ms.

Por último, para el cálculo de la matriz de movimiento se realiza la descomposición en valores singulares (SVD). En este caso, el coste computacional depende directamente del número de puntos. La descomposición en valores singulares en relación a los emparejamientos se encuentra en el cuadro~\ref{tab:svd-time}.

\begin{table}
\caption{Tiempos medios de cálculo de SVD en relación a los emparejamientos}
\label{tab:svd-time}
\centering
\begin{tabular}{ l | l }
\toprule
\textbf{Número de emparejamientos} & \textbf{Tiempo (ms)}\\
\hline\hline
50 & 1.44\\
\hline
100 & 1.64\\
\hline
200 & 1.96\\
\hline
400 & 2.17\\
\bottomrule
\end{tabular}
\end{table}

Como es de esperar, el tiempo de cómputo de la optimización RANSAC no dependerá tanto del número de emparejamientos, sino que dependerá del número de iteraciones del algoritmo. En el cuadro~\ref{tab:ransac-time} se puede ver el tiempo por número de iteraciones del algoritmo para un total de unos 100 emparejamientos por iteración.

\begin{table}
\caption{Tiempos medios de cálculo con RANSAC en relación a las iteraciones para una media de 100 emparejamientos por iteración}
\label{tab:ransac-time}
\centering
\begin{tabular}{ l | l }
\toprule
\textbf{Número de iteraciones} & \textbf{Tiempo (ms)}\\
\hline\hline
10 & 7.11\\
\hline
20 & 16.45\\
\hline
50 & 40.01\\
\bottomrule
\end{tabular}
\end{table}